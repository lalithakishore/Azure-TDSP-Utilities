## Resources ##

Microsoft provides a full spectrum of data and analytics resources, on cloud or on premise, to make your execution of data science projects scalable and efficient. These data and analytics resources include:


- Data Science Virtual Machines (both Windows and CentOS Linux)
- HDInsight Spark Clusters
- SQL Data Warehouse
- Azure Data Lake
- HDInsight Hive Clusters
- Azure File Storage
- SQL Server 2016 R Services. 

Please choose the data and analysis resources based on the needs of your projects. The following table provides a brief guidance. If you want to learn how to use the different data and analytics platforms, please click the links provided at the bottom row of the table. You will be directed to the end to end walkthrough page of the platform. 

<table>
    <tr>
        <th></th>
		<th><font size="2"><a href="https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/">DSVM</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/hdinsight-apache-spark-overview/">Azure HDInsight Spark Cluster</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/services/sql-data-warehouse/">Azure SQL Data Warehouse</a></font></th>
        <th><font size="2"><a href="(https://azure.microsoft.com/en-us/blog/introducing-azure-data-lake/">Azure Data Lake</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/hdinsight-use-hive/">Azure HDInsight Hive (Hadoop) Clusters</a></font></th>
        <th><font size="2"><a href="https://msdn.microsoft.com/en-us/library/mt604845.aspx">SQL Server 2016 R Services</a></font></th>
    </tr>
    <tr>
        <th><font size="2">Structured Data</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
    </tr>
    <tr>
        <th><font size="2">Semi-Structured Data</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red" ><i>N</i></font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
    </tr>
    <tr>
        <th><font size="2">Unstructured Data</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
    </tr>
    <tr>
        <th><font size="2">Scalable</font></th>
        <th><font size="2" color="red"><i>N</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
    </tr>
    <tr>
        <th><font size="2">Elastic</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
    </tr>
    <tr>
        <th><font size="2">Machine Learning Embedded</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="green">Y</font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="red"><i>N</i></font></th>
        <th><font size="2" color="green">Y</font></th>
    </tr>
    <tr>
        <th><font size="2">Supported Data Science Languages</font></th>
        <th><font size="2">Python,R</font></th>
        <th><font size="2">Python, Microsoft R Services, Scala</font></th>
        <th><font size="2">SQL</font></th>
        <th><font size="2">U-SQL Queries</font></th>
        <th><font size="2">Hive Queries, UDF in Python</font></th>
        <th><font size="2">SQL, R</font></th>
    </tr>
    <tr>
        <th><font size="2">End to End Data Science Walkthrough</font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-vm-do-ten-things/">Windows</a>, <a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-linux-dsvm-intro/">Linux</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-spark-overview/">Python</a>,<a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-scala-walkthrough/">Scala</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-sqldw-walkthrough/">SQL</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-data-lake-walkthrough/">U-SQL Queries</a></font></th>
        <th><font size="2"><a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-hive-walkthrough/">NYC Taxi Data</a>, <a href="https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-hive-criteo-walkthrough/">1TB Criteo Data</a></font></th>
        <th><font size="2"><a href="https://msdn.microsoft.com/en-us/library/mt683480.aspx">SQL Developers</a>, <a href="https://msdn.microsoft.com/library/mt612857.aspx">R Programmers</a></font></th>
    </tr>
</table>

In this document, we briefly describe these resources. We list these resources because either data scientists are most familiar with, or will have the sharpest learning curve to learn and start using them. More details can be found at the product pages of these resources. 

### Data Science Virtual Machine (DSVM)

The data science virtual machine contains popular tools for data science modeling and development activities. The main tools include Microsoft R Server Developer Edition, Anaconda Python distribution, Jupyter notebooks for Python and R, Visual Studio Community Edition with Python and R Tools, Power BI desktop, SQL Server Express edition. It also includes ML tools like CNTK (an Open Source Deep Learning toolkit from Microsoft), xgboost and Vowpal Wabbit.

Currently DSVM in Windows and CentOS Linux operating systems are available. You need to choose the size of the virtual machine (number of CPU cores and size of memories) based on the needs of the data science projects that you are planning to execute on the DSVM. For more details of DSVM, please refer to [Microsoft Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/). 

To know how to execute data science projects on the DSVM efficiently, please read [Ten things you can do on the Data science Virtual Machine.](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-vm-do-ten-things/)

### Azure HDInsight Spark Clusters

Apache Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Spark processing engine is built for speed, ease of use, and sophisticated analytics. Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations. Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.

When you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured. It only takes about ten minutes to create a Spark cluster in HDInsight. The data to be processed is stored in Azure Blob storage. See Use Azure Blob Storage with HDInsight.

TDSP team from Microsoft has published two end to end walkthroughs on how to use Azure HDInsight Spark Clusters to build data science solutions, in Python and Scala. More details of Azure HDInsight Spark Clusters can be found [here](https://azure.microsoft.com/en-us/documentation/articles/hdinsight-apache-spark-overview/). To learn and practice on how to build your data science solutions in Azure HDInsight Spark Clusters, please read [Data Science using **Python** with Spark on Azure](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-spark-overview/), and [Data Science using **Scala** with Spark on Azure](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-scala-walkthrough/). 

###  Azure SQL Data Warehouse
Azure SQL Data Warehouse allows you to easily scale compute in seconds without over-provisioning or over-paying. Plus, SQL Data Warehouse offers the unique option to pause compute, giving you even more freedom to better manage your cloud costs. Now bring all your data with no tradeoffs on which data to ingestâ€”run compute only on the datasets that matter.

More details of Azure SQL Data Warehouse can be found [here](https://azure.microsoft.com/en-us/services/sql-data-warehouse/). To learn and practice on how to build end to end advanced analytics solutions on SQL Data Warehouse, please follow the [The Team Data Science Process in action: using SQL Data Warehouse](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-sqldw-walkthrough/)

### Azure Data Lake
Azure data lake is as an enterprise wide repository of every type of data collected in a single place prior to any formal definition of requirements or schema. This allows every type of data to be kept without discrimination regardless of its _**size**_, _**structure**_, or how fast it is ingested. Organizations can then use Hadoop or advanced analytics to find patterns of the data. Data lakes can also serve as a repository for lower cost data preparation prior to moving curated data into a data warehouse.

More details of Azure Data Lake can be found [here](https://azure.microsoft.com/en-us/blog/introducing-azure-data-lake/). To learn and practice on how to build a scalable end to end data science solution in Azure Data Lake, please read [Scalable Data Science in Azure Data Lake: An end-to-end Walkthrough](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-data-lake-walkthrough/)

### Azure HDInsight Hive (Hadoop) Clusters

Apache Hive is a data warehouse system for Hadoop, which enables data summarization, querying, and analysis of data by using HiveQL (a query language similar to SQL). Hive can be used to interactively explore your data or to create reusable batch processing jobs.

Hive allows you to project structure on largely unstructured data. After you define the structure, you can use Hive to query that data without knowledge of Java or MapReduce. HiveQL (the Hive query language) allows you to write queries with statements that are similar to T-SQL.

For data scientists, Hive allows running Python User Defined Functions (UDFs) in Hive queries to process records. It extends the capability of Hive queries in data analysis. Specifically, it allows data scientists to conduct scalable feature engineering in languages they are mostly familiar with: SQL-like HQL and Python. 

More details of Azure HDInsight Hive Clusters can be found [here](https://azure.microsoft.com/en-us/documentation/articles/hdinsight-use-hive/). To learn and practice on how to build a scalable end to end data science solution in Azure HDInsight Hive Clusters, please read [The Team Data Science Process in action: using HDInsight Hadoop clusters](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-data-science-process-hive-walkthrough/)

### Azure File Storage 

Azure File storage is a service that offers file shares in the cloud using the standard Server Message Block (SMB) Protocol. Both SMB 2.1 and SMB 3.0 are supported. With Azure File storage, you can migrate legacy applications that rely on file shares to Azure quickly and without costly rewrites. Applications running in Azure virtual machines or cloud services or from on-premises clients can mount a file share in the cloud, just as a desktop application mounts a typical SMB share. Any number of application components can then mount and access the File storage share simultaneously.

Specifically for a data science project, you can create an Azure file storage to be the place to share the project data with your project team members. Each of them has access to the same copy of the data in the Azure file storage. They can also use this file storage to share feature sets generated during the project execution. If the project is a client engagement, your client can create an Azure file storage under his own Azure subscription to share the project data and features. In this way, the client has 100% control to the project data assets.  

### SQL Server 2016 R Services

R Services (In-database) provides a platform for developing and deploying intelligent applications that uncover new insights. You can use the rich and powerful R language and the many packages from the community to create models and generate predictions using your SQL Server data. Because R Services (In-database) integrates the R language with SQL Server, you can keep analytics close to the data and eliminate the costs and security risks associated with data movement.

R Services (In-database) supports the open source R language with a comprehensive set of SQL Server tools and technologies that offer superior performance, security, reliability and manageability. You can deploy R solutions using convenient, familiar tools, and your production applications can call the R runtime and retrieve predictions and visuals using Transact-SQL. You also get the ScaleR libraries to improve the scale and performance of your R solutions. Details can be found [here](https://msdn.microsoft.com/en-us/library/mt604845.aspx)

The TDSP team from Microsoft has published two end to end walkthroughs so either R programmers or SQL developers can lean and practice building data science solutions in SQL Server 2016 R Services. For **R Programmers**, please read [Data Science End-to-End Walkthrough](https://msdn.microsoft.com/library/mt612857.aspx). For **SQL Developers**, please read [In-Database Advanced Analytics for SQL Developers (Tutorial)](https://msdn.microsoft.com/en-us/library/mt683480.aspx)

## Appendix: Other Tools for Setting up TDSP and Executing Projects

### Install Git Credential Manager on Windows

If you are practicing TDSP on **Windows**, you will need to install _Git Credential Manager (GCM)_ in order to communicate with the git repositories. You can run the following commands in Windows PowerShell as **Administrator** to install GCM. To install GCM, you will first need to install Chocolaty. 

	iwr https://chocolatey.org/install.ps1 -UseBasicParsing | iex
	choco install git-credential-manager-for-windows -y
	

### Install Git on Linux (CentOS) Machines
Run the following bash command to install git on Linux (CentOS) machines:

	sudo yum install git


### Generate Public SSH Key on Linux (CentOS) Machines

If you are using Linux (CentOS) machines to run the git commands, you will first need to add the public SSH key of your machine to your VSTS server so that this machine can be recognized by the VSTS server. 

First, you need to generate a public SSH key, and add the key to SSH public keys in your VSTS security setting page. Run the following two commands

	ssh-keygen
	cat .ssh/id_rsa.pub

![](media/generate_ssh.PNG)

Copy the entire ssh key including _ssh-rsa_. Log in to your VSTS server. Click **<Your Name\>** at the top right corner of the page, and click **security**. Then, click **SSH public keys**, and click **+Add**. Then, paste the just copied ssh key in the text box, and save.
	
![](media/user_setting.PNG)

![](media/add_ssh.PNG)
